<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <title>Sushant Kafle</title>
        <link href="https://fonts.googleapis.com/css?family=Roboto:300|Sarabun:300" rel="stylesheet">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.2/css/all.css" integrity="sha384-/rXc/GQVaYpyDdyxK+ecHPVYJSN9bmVFBvjA/9eOB+pb3F2w2N6fc5qB9Ew5yIns" crossorigin="anonymous">
        <link rel="stylesheet" type="text/css" href="css/style.css">
        <script src="js/jquery.min.js"></script>
        <script language="javascript" type="text/javascript" src="js/script.js"></script>
    </head>
    <body bgcolor="#fff">
        <header id="header" class="hidden">
            <a href="#intro">Sushant Kafle</a>
            <nav class="links">
                <ul>
                    <li><a href="CV/skafle-cv-2019a.pdf">CV</a></li>
                    <li><a href="#research">Publications</a></li>
                    <li><a href="#projects">Projects</a></li>
                    <li><a href="#news">News</a></li>
                </ul>
            </nav>
        </header>
        <section class="highlight">
            <div class="inner">
                <h1>Sushant Kafle</h1>
                <div id="email">sushant <span id="at">@</span> mail.rit.edu</div>
                <div id="education">
                    <i>Ph.D. Candidate,</i><br/>
                    Computing and Information Science, <br/> GCCIS, RIT
                </div>
                <div id="navBar">
                    <ul id="mainNav">
                        <li><a href="CV/skafle-cv-2019a.pdf">Curriculam Viate </a></li>
                        <li><a href="#research"> Publications </a></li>
                        <li><a href="#projects"> Projects </a></li>
                        <li><a href="#news"> News </a></li>
                    </ul>
                    <ul id="subNav">
                        <li><i class="fab fa-github"></i> <a href="https://github.com/SushantKafle">Github</a> &#149;</li>
                        <li><i class="fab fa-google"></i> <a href="https://scholar.google.com/citations?user=7UqMgUUAAAAJ&hl=en">Scholar Page</a> &#149;</li>
                        <li><i class="fab fa-blogger-b"></i> <a href="http://blog.kaflesushant.com.np">Blog</a></li>
                    </ul>
                </div>
                <a class="scroll-btn" href="#intro"><span></span></a>
            </div>
        </section>
        <section id="intro">
            <div class="highlight-intro-divider"></div>
            <div class="inner">
                <div class="col-left">
                    <img style="border-radius: 50%;" src="data/2017-oct.JPG" alt="Photo of Sushant Kafle." width="225px" height="230px" />
                </div>
                <div class="col-right">
                    <h2>About Sushant</h2>
                    Sushant is a Ph.D. candidate at the Golisano College of Computing and Information Sciences at the Rochester Institute of Technology, where he specializes in accessibility for people with disabilities, human-computer interaction and computational linguistics.
                    <br/><br/>
                    <strong>Research</strong><br/>
                    My current research aims to inform the design and the evaluation of automatic speech recognition technology for use in captioning for people who are deaf or hard of hearing. In general, I am interested in building machine learning (ML) systems that model human communication with a goal to enhance human-to-human or human-to-machine interaction. My work is often heavily user-centric and involves designing, evaluating and validating these ML-systems through real-world studies and observation with the actual end users of the system.<br/><br/>

                    <strong>Roles</strong><br/>
                    I am a Graduate Research Assistant at the <a href="http://cair.rit.edu">Center of Accessibility and Inclusion Research</a> (CAIR) Lab and <a href="http://latlab.ist.rit.edu/">Linguistic Assitive Technology Lab</a> (LATlab) at RIT under the advisement of <a href="https://huenerfauth.ist.rit.edu/">Dr. Matt Huenerfauth</a>. I am also the Information Director of the <a href="http://sigaccess.org">ACM Special Interest Group on Accessible Computing</a> (SIGACCESS). <br/><br/>
                </div>
            </div>
        </section>
        <section id="research">
            <div class="intro-research-divider"></div>
            <div class="inner">
                <h1> Publications </h1>
                <div class="pretext">
                    I publish my research in top venues in Computer Accessibility, Human-Computer Interaction and Natural Language and Speech Processing.
                </div>
                <hr class="fading_style">
                <div class="pub-date">2019</div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/kafle-2019-assets.png" alt="Image showing a snippet of a typical online classroom setup with different visual section labelled such as video-stream of lecturer on the top-left corner, slides in the middle and captions at the bottom of the image." width="150px" height="100px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title" style="float:right;">Evaluating the Benefit of Highlighting Key Words in Captions for People who are Deaf or Hard of Hearing.</div>
                                <div class="pub-detail"><b>Sushant Kafle</b>, Peter Yeung and Matt Huenerfauth. <i>Annual SIGACCESS Conference on Computers and Accessibility (ASSETS'19)</i></div>
                                <div class="pub-access">[to appear]</div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/feature-fusion-2019.png" alt="Image varying distributed feature representation of word night under different prosodic contexts." width="150px" height="100px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title" style="float:right;">Fusion Strategy for Prosodic and Lexical Representations of Word Importance.</div>
                                <div class="pub-detail"><b>Sushant Kafle</b>, Cecilia O. Alm and Matt Huenerfauth. <i>International Speech Communication Association (Interspeech'19)</i></div>
                                <div class="pub-access">[to appear]</div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/speech-feats.png" alt="Image showing a RNN-based neural architecture for extracting speech-based features for words in a spoken dialogue." width="150px" height="100px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title" style="float:right;">Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken Dialogues.</div>
                                <div class="pub-detail"><b>Sushant Kafle</b>, Cecilia O. Alm and Matt Huenerfauth. <i>Speech and Language Processing for Assistive Technologies (NAACL'19)</i></div>
                                <div class="pub-access"><a href="https://www.aclweb.org/anthology/W19-1702">[access via aclweb]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>

                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/kafle-2019-taccess.png" alt="Image showing a graph of impact scores of recognition errors on the understadability of the text." width="150px" height="100px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title" style="float:right;">Predicting the Understandability of Imperfect English Captions for People who are Deaf or Hard of Hearing.</div>
                                <div class="pub-detail"><b>Sushant Kafle</b> and Matt Huenerfauth. <i>ACM Transactions on Accessible Computing (TACCESS'19)</i></div>
                                <div class="pub-access">[to appear]</div>
                            </td>
                        </tr>
                    </table>
                </div>

                <div class="pub-date">2018</div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/seita-2018.jpg" alt="Image showing three individuals (two hearing and one deaf) using a mobile app with automatic speech recognition for communication." width = "150px" height = "120px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title" style="float:right;">Behavioral Changes in Speakers who are Automatically Captioned in Meetings with Deaf or Hard-of-Hearing Peers.</div>
                                <div class="pub-detail">Matthew Seita, Khaled Albusays, <b>Sushant Kafle</b>, Michael Stinson and Matt Huenerfauth. <i>Annual SIGACCESS Conference on Computers and Accessibility (ASSETS'18)</i></div>
                                <div class="pub-access"><a href="https://dl.acm.org/citation.cfm?id=3236355">[acess via ACM-DL]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/alkharazi-2018.jpg" alt="Image showing ASL sentences with variable-length pauses inserted in between words." width = "150px" height = "120px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Modeling the Speed and Timing of American Sign Language to Generate Realistic Animations.</div>
                                <div class="pub-detail">Sedeeq Al-khazraji, Larwan Berke, <b>Sushant Kafle</b>, Peter Yeung and Matt Huenerfauth. <i>Annual SIGACCESS Conference on Computers and Accessibility (ASSETS'18)</i></div>
                                <div class="pub-award"><img src="https://assets17.sigaccess.org/images/award.png" alt=""> Best Paper Award</div>
                                <div class="pub-access"><a href="https://dl.acm.org/citation.cfm?id=3236356">[acess via ACM-DL]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/kafle-2018.jpg" alt="Image showing a sentence, what do you think is the biggest problem, with importance annotation for each word. Words like, biggest and problem, received high importance." width = "150px" height = "120px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts.</div>
                                <div class="pub-detail"><b>Sushant Kafle</b>, Matt Huenerfauth. <i>International Conference on Language Resources and Evaluation (LREC'18)</i></div>
                                <div class="pub-access"><a href="https://arxiv.org/abs/1801.09746">[access pre-print at arxiv]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/berke-2018.jpg" alt="Image showing a speaker speaking in front of the camera with captions being displayed underneath." width = "150px" height = "120px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Methods for Evaluation of Imperfect Captioning Tools by Deaf or Hard-of-Hearing Users at Different Reading Literacy Levels.</div>
                                <div class="pub-detail">Larwan Berke, <b>Sushant Kafle</b>, Matt Huenerfauth. <i>ACM Conference on Human Factors in Computing Systems (CHI'18) </i></div>
                                <div class="pub-award"><img src="https://assets17.sigaccess.org/images/award.png" alt=""> Best Paper Honarable Mention</div>
                                <div class="pub-access"><a href="https://dl.acm.org/authorize?N650482">[access via ACM-DL]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/alkharazi-2017.png" alt="Image showing a sign-language avatar delivering an ASL sentence." width = "150px" height = "120px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Modeling and Predicting the Location of Pauses for the Generation of Animations of American Sign Language.</div>
                                <div class="pub-detail">Sedeeq Al-khazraji, <b>Sushant Kafle</b>, Matt Huenerfauth. <i>International Conference on Language Resources and Evaluation (LREC'18)</i></div>
                                <div class="pub-access">[to appear]</div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-date">2017</div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/kafle-2017.jpg" img="Image showing two versions of a caption from a meeting context and a subjective-rating scale underneath." width = "150px" height = "120px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Evaluating the Usability of Automatically Generated Captions for People who are Deaf or Hard of Hearing.</div>
                                <div class="pub-detail"><b>Sushant Kafle</b>, Matt Huenerfauth. <i>Annual SIGACCESS Conference on Computers and Accessibility (ASSETS'17)</i></div>
                                <div class="pub-award"><img src="https://assets17.sigaccess.org/images/award.png" alt=""> Best Paper Award</div>
                                <div class="pub-access"><a href="http://dl.acm.org/authorize?N41803">[access via ACM-DL]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-date">2016</div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/kafle-2016.jpg" alt="A graph showing the importance of various semantic properties of text on the impact of ASR errors. Properties like the length of the word is shown to have heighest impact of error quality." width = "150px" height = "120px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Effect of Speech Recognition Errors on Text Understandability for People who are Deaf or Hard of Hearing.</div>
                                <div class="pub-detail"><b>Sushant Kafle</b>, Matt Huenerfauth. <i>Speech and Language Processing for Assistive Technologies (INTERSPEECH'16)</i></div>
                                <div class="pub-access"><a href="http://scholarworks.rit.edu/cgi/viewcontent.cgi?article=1915&context=other">[access via RIT-Scholarworks]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
            </div>
            <br/>
        </section>
        <section id="projects">
            <div class="research-projects-divider"></div>
            <div class="inner">
                <h1>Projects</h1>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/kafle-2018.jpg" alt="Image showing a sentence, what do you think is the biggest problem, with importance annotation for each word. Words like, biggest and problem, received high importance." width="150px" height="100px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Word Importance Labeler</div>
                                <div class="pub-detail">Developing a tool with a suite of metrics for evaluating the quality automatically generated transcripts of classroom lectures based on word importance information. The tool was developed as a part of a research project at <a href="http://www.ntid.rit.edu/"> National Technical Institute for Deaf (NTID) </a> which investigated the usability of automatic captioning for classrooms.</div>
                                <div class="pub-access"><a href="https://github.com/SushantKafle/speechtext-wimp-labeler">[demo]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/speech-feats.png" alt="Image showing a RNN-based neural architecture for extracting speech-based features for words in a spoken dialogue." width="150px" height="100px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Speech Analysis for Word Importance Modeling</div>
                                <div class="pub-detail">Investigated various acoustic-prosodic features from human speech to see if they provide clues about the importance of word being spoken; importance defined in terms of the contribution of the word in understanding the meaning of a spoken utterance.</div>
                                <div class="pub-access"><a href="http://kaflesushant.com.np/Speech-based-WImp-Demo/">[demo]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <div class="pub-item">
                    <table border="0px">
                        <tr>
                            <td>
                                <div class="pub-img"><img src="data/thumbnails/error-category.png" alt="Image showing various type of ASR errors with color-bards highlighting the percentage of their occurence." width="150px" height="100px" class="zoom" /></div>
                            </td>
                            <td>
                                <div class="pub-title">Speech Recognition Error Analysis.</div>
                                <div class="pub-detail">Categorized and analyzed different types of errors produced by Sphinx4 Speech Recognition System on 100-hrs of speech recordings from LibriSpeech Corpus. Implemented novel output alignment modules to account for fuzzy time-stamp matching and, one to many and many to one substitution errors. Created a local compute cluster to make speech recognition faster.</div>
                                <div class="pub-access"><a href="#">[demo]</a></div>
                            </td>
                        </tr>
                    </table>
                </div>
                <ul class="labels">
                    <li style="text-decoration: none;">Miscellenious:</li>
                    <li><a href="https://github.com/SushantKafle/3D-Maze-Simulation-and-Rendering#input">3D Maze Simulator</a></li>
                    <li><a href="https://www.youtube.com/watch?v=vnps_VzTjPo">3D Rubik's Cube Simulator and Solver</a></li>
                    <li><a href="papers/ioeconf.pdf">Interest Rate Prediction of Banks</a></li>
                    <li><a href="http://kaflesushant.com.np/BusyNote">BusyNote</a></li>
                    <li><a href="https://github.com/SushantKafle/PerlinNoise">Perlin Noise Implemetation</a></li>
                    <li><a href="https://github.com/SushantKafle/kabach#-some-quick-snapshots-">Kabach</a></li>
                    <li><a href="http://www.slideshare.net/getsushant/easy-yatra-presentation-new-style">Easy Yatra</a></li>
                    <li><a href="https://github.com/SushantKafle/MarchingSquares">Marching Square</a></li>
                    <li><a href="https://github.com/SushantKafle/QuickHull2D">Quick Hull</a></li>
                    <li><a href="https://github.com/SushantKafle/DecisionTree#live-at-">Decision Tree</a></li>
                    <li><a href="http://doece.ioe.edu.np/blog/?p=23">Parikshya</a></li>
                    <li><a href="https://github.com/SushantKafle/TripletExtraction">Triplet Extraction From Sentence</a></li>
                    <li><a href="https://github.com/SushantKafle/findout">Find Out</a></li>
                    <li><a href="https://github.com/SushantKafle/FartyBird">Farty Bird</a></li>
                    <li><a href="https://github.com/SushantKafle/DBSCAN">DBScan</a></li>
                    <li><a href="https://github.com/SushantKafle/Excel2HTML">Excel2HTML</a></li>
                    <li><a href="https://github.com/SushantKafle/GLSL-Sandbox">GLSL sandbox</a></li>
                </ul>
            </div>
            <br/>
        </section>
        <section id="news">
            <div class="projects-news-divider"></div>
            <div class="inner">
                <h1> Timeline and Events </h1>
                <table class="table_scroll styled_table custom_scroll">
                    <tbody>

                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>June, 2019</h4>
                            </td>
                            <td> Our work on "Evaluating the Benefit of Highlighting Key Words in Captions for People who are Deaf or Hard of Hearing" has been accepted at the <a href="https://assets19.sigaccess.org">ASSETS 2019</a> conference!</td>
                        </tr>

                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>June, 2019</h4>
                            </td>
                            <td> Attended the <a href="https://hcic.org/hcic2019/index.phtml">HCIC 2019 Workshop</a> on the Future of Work held in Pajaro Dunes, Watsonville, CA. Also, got a chance to present my Ph.D. thesis work as a part of the poster session at the workshop.</td>
                        </tr>


                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>June, 2019</h4>
                            </td>
                            <td> Happy to annouce that our paper "Fusion Strategy for Prosodic and Lexical Representations of Word Importance." was accepted at the <a href="interspeech2019.org">Interspeech 2019</a> conference.</td>
                        </tr>

                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>June, 2019</h4>
                            </td>
                            <td> Attended <a href="https://naacl2019.org" >NAACL 2019</a> conference and participated in the <a href="slpat.org/slpat2019">SLPAT workshop</a> with our paper "Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken Dialogues."</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>April, 2019</h4>
                            </td>
                            <td> Our journal paper on "Predicting the Understandability of Imperfect English Captions for People who are Deaf or Hard of Hearing." was accepted at ACM Transaction of Accessible Computing (TACCESS).</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>October, 2018</h4>
                            </td>
                            <td> <img src="https://assets17.sigaccess.org/images/award.png" alt=""> Co-presented our paper on "Modeling the Speed and Timing of American Sign Language to Generate Realistic Animations." at the <a href="https://assets18.sigaccess.org/" >ASSETS 2018</a> conference which was also recognized with the Best Paper Award in the conference.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>June, 2018</h4>
                            </td>
                            <td>Participating in the summer internship program at Google in Seattle office till September, 2018.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>June, 2018</h4>
                            </td>
                            <td>Two of our papers from the lab, which I am pleased to have contributed to, has been accepted at the <a href="https://assets18.sigaccess.org/" >ASSETS 2018</a> conference.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>June, 2018</h4>
                            </td>
                            <td>Sucessfully defended my Ph.D. thesis proposal. Officially a Ph.D. candidate now (yay!). </td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>January, 2018</h4>
                            </td>
                            <td> Our workshop paper "Modeling and Predicting the Location of Pauses for the Generation of Animations of American Sign Language" was accepted at the <a href="https://www.sign-lang.uni-hamburg.de/lrec/workshops.html" >Sign Langague Workshop</a> at LREC 2018.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>December, 2017</h4>
                            </td>
                            <td> <img src="https://assets17.sigaccess.org/images/award.png" alt=""> Our paper "Methods for Evaluation of Imperfect Captioning Tools by Deaf or Hard-of-Hearing Users at Different Reading Literacy Levels" was accepted at the <a href="https://chi2018.acm.org/" >CHI 2018</a> conference and was nominated for a Best Paper Honarable Mention award (ranked among the top 5% of all submissions to the SIGCHI 2018 conference).</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>December, 2017</h4>
                            </td>
                            <td> Our paper "A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts." was accepted at the <a href="http://lrec2018.lrec-conf.org/en/" >LREC 2018</a> conference.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>November, 2017</h4>
                            </td>
                            <td> <img src="https://assets17.sigaccess.org/images/award.png" alt=""> Our <a href="https://assets17.sigaccess.org/" >ASSETS 2017</a> paper won the <a href="http://www.sigaccess.org/2017/11/2017-best-paper/">"Best Paper Award"</a>.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>September, 2017</h4>
                            </td>
                            <td> We announce the creation of the Corpus of Word Importance Annotations, more details <a href="http://latlab.ist.rit.edu/lrec2018">here</a>.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>July, 2017</h4>
                            </td>
                            <td> <img src="https://assets17.sigaccess.org/images/award.png" alt=""> Our paper "Evaluating the Usability of Automatically Generated Captions for People who are Deaf or Hard of Hearing" was accepted at the <a href="https://assets17.sigaccess.org/" >ASSETS 2017</a> conference and was nominated for a Best Paper Award.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>May, 2017</h4>
                            </td>
                            <td> Helped facilitate the <a href="https://www.nsf.gov/crssprgm/reu/">Research Experience for Undergraduates (REU)</a> program at the CAIR lab.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>October, 2016</h4>
                            </td>
                            <td> Participated and presented at <a href="https://assets16.sigaccess.org/">ASSETS Doctoral Consortium 2016</a>.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>July, 2016</h4>
                            </td>
                            <td> Our paper "Effect of Speech Recognition Errors on Text Understandability for People who are Deaf or Hard of Hearing" was accepted at <a href="http://www.slpat.org/slpat2016/">SLPAT 2016</a> workshop.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>May, 2016</h4>
                            </td>
                            <td> Sucessfully defended the PhD Research Potential Assesment.</td>
                        </tr>
                        <tr>
                            <td style="width:25%;text-align:center;">
                                <h4>August, 2015</h4>
                            </td>
                            <td> Joined RIT for doctoral studies in the <a href="https://www.rit.edu/gccis/">Golisano College of Computing and Information Sciences</a>. Started working as a research assistant at the <a href="http://cair.rit.edu/">CAIR Lab</a>.</td>
                        </tr>
                    </tbody>
                </table>
                <br/>
            </div>
        </section>
        </center>
        <!-- Start of StatCounter Code for Default Guide -->
        <script type="text/javascript">
            var sc_project=9911916;
            var sc_invisible=1;
            var sc_security="7cee0cab";
            var scJsHost = (("https:" == document.location.protocol) ?
            "https://secure." : "http://www.");
            document.write("<sc"+"ript type='text/javascript' src='" +
            scJsHost+
            "statcounter.com/counter/counter.js'></"+"script>");
        </script>
        <noscript>
            <div class="statcounter"><a title="hits counter"
                href="http://statcounter.com/free-hit-counter/"
                target="_blank"><img class="statcounter"
                src="http://c.statcounter.com/9911916/0/7cee0cab/1/"
                alt="hits counter"></a></div>
        </noscript>
        <!-- End of StatCounter Code for Default Guide -->
    </body>
</html>